# Implementation Plan: AI-Native Physical AI & Humanoid Robotics Textbook

**Branch**: `001-textbook-spec` | **Date**: 2025-12-06 | **Spec**: [specs/001-textbook-spec/spec.md](spec.md)
**Input**: Comprehensive textbook with RAG chatbot, authentication, personalization, and multi-language support

**Note**: This plan is generated by `/sp.plan` and strictly adheres to Constitution v1.0.0 (Rigor & Accuracy, Academic Clarity, Reproducibility) and the feature specification (5 user stories, 30 requirements, 30 success criteria).

## Summary

Build an AI-Native Physical AI & Humanoid Robotics Textbook delivering four sequential modules (ROS 2, Digital Twin, AI-Robot Brain, VLA) via a decoupled Docusaurus frontend and FastAPI backend. Integrate RAG-powered chatbot (Qdrant + LLM) for interactive learning, Better-Auth for user authentication, and Neon PostgreSQL for profile persistence and personalization. Support multi-language content delivery via reusable backend services. Prioritize academic rigor, code reproducibility, and pedagogical clarity per Constitution mandate.

## Technical Context

**Language/Version**: Python 3.11+ (backend), Node.js 20+ (frontend with TypeScript)
**Primary Dependencies**:
  - **Frontend**: Docusaurus 3.0+, React 18+, Tailwind CSS
  - **Backend**: FastAPI, Pydantic, SQLAlchemy ORM
  - **Auth**: Better-Auth library (with Neon adapter)
  - **Vector DB**: Qdrant (self-hosted or managed cloud)
  - **LLM Integration**: OpenAI GPT-4 API or Claude API (with fallback)
  - **Database**: Neon PostgreSQL (managed)

**Storage**: Neon PostgreSQL (user profiles, lesson metadata, progress tracking, chat logs) + Qdrant vector database (lesson embeddings)

**Testing**: pytest (backend unit/integration), Vitest (frontend), contract tests via OpenAPI validation

**Target Platform**: Web browsers (Chrome, Firefox, Safari, Edge latest 2 versions); Linux/macOS/Windows development environments

**Project Type**: Web application (decoupled frontend + backend per Constitution Principle V)

**Performance Goals**:
  - Page load: ≤3 seconds (p95) on 5 Mbps broadband
  - Chatbot response: ≤5 seconds (p95)
  - System uptime: ≥99.5% (max 3.6 hours downtime/month)
  - Concurrent users: ≥1000 without degradation

**Constraints**:
  - Code examples MUST execute without modification in documented environment (Python 3.11+, ROS 2 Humble+, Gazebo 11+)
  - All technical claims MUST cite official documentation or peer-reviewed sources
  - Session-based authentication with HTTPS-only
  - GDPR/CCPA compliance for EU/California users

**Scale/Scope**:
  - 4 modules × 30+ lessons minimum = 120+ total lessons
  - 7 key data entities (User, Lesson, Module, UserProgress, ChatbotQuery, LessonEmbedding, ContentTranslation)
  - Support for ≥500 registered users within 90 days
  - 3 language versions (English, Spanish, Mandarin)

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

### Core Principle Alignment

**I. Rigor & Accuracy** ✅ PASS
- Code examples target documented, official APIs (ROS 2 Humble, Python 3.11+, Gazebo 11+)
- All content claims will cite official documentation (ROS 2 docs, NVIDIA Isaac Sim, control systems textbooks)
- Execution environment documented and reproducible
- Code examples tested end-to-end before publication

**II. Academic Clarity** ✅ PASS
- Docusaurus frontend optimized for progressive, modular learning (lesson-by-lesson navigation)
- Terminology defined at first use with formal precision
- Four-module structure supports sequential learning with clear prerequisites
- Examples scaled to pedagogical appropriateness (not overwhelming complexity)

**III. Reproducibility** ✅ PASS
- Complete setup instructions provided (dependencies, environment configuration)
- Code snippets copy-paste ready; no modifications required
- Version pinning enforced (Python 3.11+, ROS 2 Humble+, Gazebo 11+)
- All tutorials tested and verified before launch

**IV. Content Structure: Four-Module Format** ✅ PASS
- Rigid adherence to: ROS 2 Fundamentals → Digital Twin → AI-Robot Brain → VLA
- Sequential prerequisites clearly marked in learning path
- No deviations permitted (enforced by content review gate)

**V. Architecture Mandate: Decoupled Frontend & Backend** ✅ PASS
- Docusaurus frontend (React, Node.js) communicates via REST API only
- FastAPI backend handles all dynamic logic (RAG, auth, personalization, translation)
- No direct coupling or monolithic patterns
- Clear OpenAPI contract published

**VI. Reusability Mandate** ✅ PASS
- RAG chatbot: Reusable service with published API contract
- Translation pipeline: Reusable service deployable independently
- Personalization engine: Reusable service consuming user profile data
- All services include unit/integration tests and deployment docs

**Gate Status**: ✅ ALL GATES PASS - Proceed to Phase 0

## Project Structure

### Documentation (this feature)

```text
specs/001-textbook-spec/
├── spec.md              # Feature specification (User Stories 1-5, 30 Requirements, 30 Success Criteria)
├── plan.md              # This file (Architecture, Research, Technical Context, Design Decisions)
├── research.md          # Phase 0 output (Technology decisions, best practices, content sources)
├── data-model.md        # Phase 1 output (Entity definitions, schema, relationships)
├── quickstart.md        # Phase 1 output (Dev environment setup, running locally)
├── contracts/           # Phase 1 output (OpenAPI specs for all backend services)
│   ├── content-api.yaml
│   ├── auth-api.yaml
│   ├── chatbot-api.yaml
│   ├── personalization-api.yaml
│   └── translation-api.yaml
├── checklists/
│   └── requirements.md   # Quality validation checklist
└── tasks.md             # Phase 2 output (/sp.tasks command - NOT created by /sp.plan)
```

### Source Code (Repository Root - Decoupled Web Application)

```text
frontend/
├── package.json
├── docusaurus.config.ts
├── src/
│   ├── components/          # Reusable React components
│   │   ├── Chatbot/
│   │   ├── LessonViewer/
│   │   ├── ModuleRoadmap/
│   │   └── UserProfile/
│   ├── pages/               # Docusaurus doc pages (Markdown + React)
│   │   ├── ROS2Fundamentals/     # Module 1
│   │   ├── DigitalTwin/          # Module 2
│   │   ├── AIRobotBrain/         # Module 3
│   │   └── VLA/                  # Module 4
│   ├── services/            # Frontend API clients
│   │   ├── api.client.ts    # Shared REST client
│   │   ├── auth.service.ts
│   │   └── chatbot.service.ts
│   └── styles/              # Tailwind CSS customizations
├── public/                  # Static assets (diagrams, images)
└── tests/
    ├── unit/                # Component tests (Vitest)
    └── e2e/                 # End-to-end tests (Playwright)

backend/
├── pyproject.toml
├── requirements.txt         # Python dependencies (FastAPI, Pydantic, SQLAlchemy, etc.)
├── src/
│   ├── main.py             # FastAPI application entry point
│   ├── config.py           # Environment config (Neon URL, Qdrant endpoint, LLM keys)
│   ├── models/             # SQLAlchemy ORM models
│   │   ├── user.py
│   │   ├── lesson.py
│   │   ├── module.py
│   │   ├── progress.py
│   │   ├── chatbot_query.py
│   │   └── content_translation.py
│   ├── api/                # FastAPI route handlers (organized by service)
│   │   ├── auth.py         # Better-Auth integration + profile endpoints
│   │   ├── content.py      # Lesson/module serving
│   │   ├── chatbot.py      # RAG pipeline (Qdrant + LLM)
│   │   ├── personalization.py   # Recommendation engine
│   │   └── translation.py  # Multi-language service
│   ├── services/           # Business logic layer
│   │   ├── auth_service.py
│   │   ├── rag_service.py  # Qdrant + embedding + LLM
│   │   ├── personalization_service.py
│   │   └── translation_service.py
│   ├── schemas/            # Pydantic request/response models
│   │   └── *.py
│   ├── db/                 # Database connection + migrations
│   │   ├── session.py      # SQLAlchemy session
│   │   └── alembic/        # Database migration scripts
│   └── utils/              # Utility functions
│       ├── embeddings.py   # LLM + embedding logic
│       └── validators.py
└── tests/
    ├── unit/               # Unit tests (pytest)
    ├── integration/        # Integration tests (FastAPI TestClient + Neon test DB)
    └── contract/          # Contract tests (OpenAPI validation)

docs/
├── ARCHITECTURE.md         # System architecture diagram & explanation
├── DEV_SETUP.md            # Local development guide
├── DEPLOYMENT.md           # Production deployment guide
└── API_CONTRACTS.md        # OpenAPI reference

.github/
└── workflows/
    └── ci.yaml             # CI/CD pipeline (test, lint, build)
```

**Structure Decision**: **Web application with decoupled frontend and backend** (Option 2)
- **Frontend**: Docusaurus (React, TypeScript) for content delivery and UX
- **Backend**: FastAPI (Python) for all dynamic logic (auth, RAG, personalization, translation)
- **Communication**: REST API via OpenAPI contracts
- **Databases**: Neon PostgreSQL (user/content/progress) + Qdrant vector DB (embeddings)
- **Rationale**: Aligns with Constitution Principle V (decoupled architecture); enables independent evolution, testing, and deployment of frontend and backend

## Complexity Tracking

**Status**: ✅ No violations. All decisions aligned with Constitution principles. No complexity justification needed.

---

## Architecture Sketch

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        DECOUPLED SYSTEM ARCHITECTURE                        │
└─────────────────────────────────────────────────────────────────────────────┘

┌──────────────────────────────┐
│  FRONTEND (Docusaurus + React)│
│  Node.js 20+ / TypeScript     │
├──────────────────────────────┤
│ • LessonViewer               │
│ • ModuleRoadmap              │
│ • ChatbotUI                  │
│ • UserProfile                │
│ • LanguageSelector           │
└──────────────┬───────────────┘
               │
               │ REST API (HTTPS)
               │ OpenAPI Contract
               │
┌──────────────▼───────────────────────────────────────────────────────┐
│              BACKEND (FastAPI + Python 3.11+)                        │
│                                                                      │
│  ┌──────────────────┐  ┌──────────────────┐  ┌──────────────────┐  │
│  │   Auth Service   │  │ Content Service  │  │ Chatbot Service  │  │
│  │ • Better-Auth    │  │ • Lesson serving │  │ • RAG pipeline   │  │
│  │ • Profile mgmt   │  │ • Module metadata│  │ • Query handling │  │
│  │ • Rate limiting  │  │ • Progress track │  │ • Citation gen   │  │
│  └──────────────────┘  └──────────────────┘  └──────────────────┘  │
│                                                                      │
│  ┌──────────────────┐  ┌──────────────────┐                         │
│  │ Personalization  │  │  Translation     │                         │
│  │ Service          │  │  Service         │                         │
│  │ • Recommendations│  │ • Content i18n   │                         │
│  │ • Path logic     │  │ • Multi-language │                         │
│  └──────────────────┘  └──────────────────┘                         │
└──────────────┬──────────────┬──────────────┬───────────────────────┘
               │              │              │
        REST API Calls   REST API Calls  REST API Calls
               │              │              │
     ┌─────────▼──────────────▼──────────────▼──────────┐
     │     PERSISTENCE & VECTOR LAYERS                 │
     ├─────────────────────────────────────────────────┤
     │  Neon PostgreSQL              Qdrant Vector DB  │
     │  ┌─────────────────────────┐  ┌──────────────┐  │
     │  │ • Users                 │  │ • Embeddings │  │
     │  │ • Lessons & Modules     │  │ • Similarity │  │
     │  │ • UserProgress          │  │   search     │  │
     │  │ • ChatbotQueries        │  │              │  │
     │  │ • ContentTranslations   │  │              │  │
     │  └─────────────────────────┘  └──────────────┘  │
     └─────────────────────────────────────────────────┘
       │                         │
       │ (SQLAlchemy ORM)        │ (Python client lib)
       │                         │
     ┌─▼─────────────────────────▼──────────────────┐
     │      External Services & APIs                │
     ├──────────────────────────────────────────────┤
     │  • OpenAI GPT-4 / Claude (LLM)              │
     │  • Translation APIs (external or internal)  │
     └──────────────────────────────────────────────┘

Data Flow (RAG Chatbot Example):
1. User query → Frontend
2. Frontend → Backend (POST /api/chatbot/query)
3. Backend embedding → Qdrant (semantic search)
4. Retrieved passages → LLM context
5. LLM → Response with citations
6. Response → Frontend → User
```

---

## Section Structure: Four Modules Across Phases A-D

This implementation plan maps the four textbook modules across the four project phases, enabling parallel content generation and technical development:

### Phase A: Research (Concurrent with Setup)
**Duration**: Week 1-2 | **Owner**: Content + Tech Lead

**Module Priority**: ROS 2 Fundamentals (foundation for all others)

**Tasks**:
- Research ROS 2 Humble APIs, best practices, official documentation
- Identify peer-reviewed robotics textbooks and curricula
- Research Gazebo integration patterns and simulation best practices
- Review NVIDIA Isaac concepts and control systems theory
- Document sources and create citation database (APA format required per Constitution)

**Output**: `research.md` with technology decisions, content sources, integration patterns

### Phase B: Foundation (Parallel with Phase A Research)
**Duration**: Week 2-4 | **Owner**: DevOps + Backend Lead

**Modules Enabled**: All (infrastructure supports all four)

**Tasks**:
- Setup Docusaurus project (frontend)
- Initialize FastAPI application (backend)
- Configure Neon PostgreSQL and schema
- Setup Qdrant vector database
- Integrate Better-Auth for authentication
- Create OpenAPI contracts
- Setup CI/CD pipeline

**Output**: Working dev environment, deployed infrastructure, API contracts

### Phase C: Analysis (Parallel with Phase A-B)
**Duration**: Week 4-8 | **Owner**: Content Authors + Backend Engineers

**Module Sequencing**:
1. **ROS 2 Fundamentals** (Weeks 4-5): Core framework, nodes, topics, services
   - 30+ lessons on ROS concepts, CLI, Python node development
   - All code examples tested in ROS 2 Humble environment

2. **Digital Twin & Simulation** (Weeks 5-6): Gazebo, virtual prototyping
   - 30+ lessons on Gazebo integration, simulation physics
   - Bridge content from ROS 2 module

3. **AI-Robot Brain** (Weeks 6-7): Perception, decision-making, learning
   - 30+ lessons on AI concepts applied to robotics
   - Build on Digital Twin simulation knowledge

4. **VLA - Vision Language Action** (Weeks 7-8): Multimodal reasoning
   - 30+ lessons on language models, embodied AI
   - Integrate all prior modules

**Parallel Tasks**:
- RAG pipeline development (Qdrant + embedding + LLM)
- User authentication implementation (Better-Auth + Neon)
- Content ingest and vectorization system

**Output**: All four modules with 120+ lessons, RAG pipeline ready, auth system functional

### Phase D: Synthesis (Weeks 8-10)
**Duration**: Week 8-10 | **Owner**: Full Team

**Tasks**:
- Personalization engine (recommendation algorithm)
- Translation pipeline setup (English → Spanish, Mandarin)
- Integration testing across all modules
- Quality validation and accuracy review
- Performance optimization
- Final deployment and monitoring

**Output**: Complete textbook with all features, deployed to production

---

## Research Approach

### Research-Concurrent Writing Process

Content generation happens **in parallel with technical setup** to maximize efficiency while maintaining Constitution mandates:

#### Phase 0: Research Foundation (Week 1-2)
1. **Deep Dive Research** (conducted by agents)
   - ROS 2 official documentation (ros.org)
   - NVIDIA Isaac documentation
   - Control systems theory (peer-reviewed papers)
   - Educational best practices (pedagogical research)

2. **Source Validation** (per Constitution Principle I)
   - Every claim backed by official docs or peer-reviewed source
   - APA citations embedded in lesson markdown
   - Fact-check matrix created: Claim → Source → Verification Status

3. **Deliverable**: `research.md`
   ```markdown
   ## Technology Decisions

   ### ROS 2 Version Selection
   **Decision**: Target ROS 2 Humble
   **Rationale**: [Long-term support, stable APIs, wide adoption]
   **Sources**:
   - Official ROS 2 Release Documentation
   - ROS 2 Design Document (REP-2000)
   **Alternatives Considered**: ROS 2 Iron, ROS 2 Rolling
   **Why Humble Won**: [Stability vs. bleeding edge trade-off analysis]

   [Similar structure for embedding models, LLM selection, etc.]
   ```

#### Phase 1: Parallel Writing & Tech Build (Week 2-4)
- **Authors**: Write ROS 2 Fundamentals lessons using research as source material
- **Engineers**: Build frontend/backend infrastructure simultaneously
- **Quality Gate**: Every code example in drafted lessons tested in ROS 2 Humble environment

#### Phase 2: Content Generation at Scale (Week 4-8)
- **Authors**: Write modules 2-4 with increasing complexity
- **Engineers**: Implement RAG pipeline while content grows
- **Feedback Loop**: Authors can request code examples; engineers provide immediately
- **Quality Gate**: All 120+ lessons peer-reviewed for accuracy (Constitution Principle I)

#### Phase 3: Integration & Synthesis (Week 8-10)
- **Full Team**: Integrate all components
- **Testing**: Cross-module validation, accuracy testing, performance tuning
- **Final Gate**: Specification success criteria verified

### Content Generation Workflow

```
Content Author
     │
     ├─ Research phase findings
     ├─ Official documentation
     ├─ Code examples
     │
     ▼
 Lesson Draft (Markdown)
     │
     ├─ APA citations embedded
     ├─ Code snippets included
     ├─ Diagrams/images referenced
     │
     ▼
 Code Example Testing
     │
     ├─ Run in ROS 2 Humble env
     ├─ Verify no modifications needed
     ├─ Document all dependencies
     │
     ▼
 Accuracy Review Gate
     │
     ├─ Cross-check claims vs. sources
     ├─ Verify reproducibility
     ├─ Approve for ingest
     │
     ▼
 Lesson Published
     │
     ├─ Indexed in Qdrant
     ├─ Available in frontend
     ├─ Searchable via RAG chatbot
```

### Citation & Rigor Standards

Every lesson MUST:
1. Cite official documentation for frameworks/APIs (e.g., "ros.org docs, Section X")
2. Cite peer-reviewed papers for theory (e.g., "Smith et al., 2023")
3. Include complete code examples with:
   - Dependency version pinning
   - Environment setup instructions
   - Execution validation proof
4. Include diagrams with sources (original, adapted from ref, or official)

**Tools**:
- Citation manager: Zotero (exported to BibTeX)
- Code testing: Automated pytest integration per module
- Accuracy tracking: Spreadsheet linking lesson → claims → sources → verification status

---

## Quality Validation

Quality gates enforce Constitution mandates at every stage:

### Gate 1: Content Accuracy (Phase 0-1)
**Trigger**: Before lesson publication

**Checks**:
- [ ] All APIs match official documentation (ROS 2 Humble, Python 3.11+)
- [ ] All code examples execute without modification in documented environment
- [ ] All claims cite official docs or peer-reviewed sources (APA format)
- [ ] Diagrams accurately represent system architecture
- [ ] Terminology defined at first use with formal precision

**Owner**: Content Lead + Subject Matter Expert

**Failure Action**: Return to author with specific violations marked

### Gate 2: Reproducibility (Phase 1-2)
**Trigger**: Before RAG indexing

**Checks**:
- [ ] Code examples include complete setup steps (dependencies, environment config)
- [ ] All code copy-paste ready (no modifications required)
- [ ] Version pinning specified for all dependencies
- [ ] Test harness passes end-to-end (pytest suite for all code examples)
- [ ] Instructions match documented execution environment

**Owner**: QA Engineer

**Failure Action**: Request updated code/instructions from author

### Gate 3: Accessibility & Pedagogy (Phase 2-3)
**Trigger**: Before content release

**Checks**:
- [ ] Learning objectives clear and measurable
- [ ] Content progression logical (fundamentals → advanced)
- [ ] Examples illustrate concepts without overwhelming complexity
- [ ] Cross-module prerequisites marked
- [ ] Readability score ≥ 12th grade level (Flesch-Kincaid)

**Owner**: Educational Content Reviewer

**Failure Action**: Simplify language or add clarifications

### Gate 4: System Performance (Phase 3)
**Trigger**: Before production deployment

**Checks**:
- [ ] Page load time ≤ 3 seconds (p95) on 5 Mbps connection
- [ ] Chatbot response ≤ 5 seconds (p95)
- [ ] Concurrent user load ≥ 1000 without degradation
- [ ] Error rate < 0.1% (5xx errors)

**Owner**: DevOps Lead

**Failure Action**: Performance optimization sprint

---

## Decisions Needing Documentation (ADR Candidates)

These architectural decisions require explicit documentation via Architecture Decision Records:

### ADR-001: Embedding Model Selection for RAG
**Issue**: Which embedding model to use (OpenAI, HuggingFace, Anthropic)?
**Options**:
- **OpenAI text-embedding-3-large**: High quality, vendor lock-in, paid API
- **HuggingFace all-MiniLM-L6-v2**: Free, open-source, lower quality
- **Anthropic embeddings** (when available): Aligned with our LLM choice

**Decision Needed**: Trade-off between quality, cost, and independence
**Impact**: Affects RAG accuracy and operational costs long-term

### ADR-002: LLM Provider for Chatbot Responses
**Issue**: OpenAI GPT-4 vs. Claude vs. self-hosted open model?
**Options**:
- **OpenAI GPT-4**: Highest quality, reliable, vendor lock-in
- **Claude (Anthropic)**: Strong reasoning, constitution-aligned
- **Llama 2 (self-hosted)**: Full control, lower latency, maintenance burden

**Decision Needed**: Balance quality, reliability, cost, and operational overhead
**Impact**: Affects chatbot accuracy, response time, and long-term flexibility

### ADR-003: Better-Auth vs. Custom Auth Implementation
**Issue**: Should we use Better-Auth library or build custom authentication?
**Options**:
- **Better-Auth**: Faster development, opinionated, potential vendor lock-in
- **Custom (JWT + Flask-Login patterns)**: Full control, maintenance burden, slower

**Decision Needed**: Development speed vs. flexibility
**Impact**: Affects security posture, maintenance burden, extensibility

### ADR-004: Translation Strategy (Human vs. Machine)
**Issue**: How to translate lessons to Spanish and Mandarin?
**Options**:
- **Human translation**: Higher quality, slower, expensive
- **Machine translation (OpenAI, Google Translate API)**: Faster, lower cost, lower quality
- **Hybrid**: Human review of machine output

**Decision Needed**: Quality vs. speed vs. cost trade-offs
**Impact**: Affects translation quality, timeline, and operational costs

### ADR-005: Qdrant Deployment (Self-hosted vs. Cloud-managed)
**Issue**: Should Qdrant run on-premises or use managed Qdrant Cloud?
**Options**:
- **Self-hosted**: Full control, lower cost at scale, ops complexity
- **Qdrant Cloud**: Managed SLA, simpler ops, vendor lock-in, ongoing cost

**Decision Needed**: Control vs. simplicity trade-off
**Impact**: Affects operational overhead, SLA guarantees, cost structure

**Status**: These ADRs will be formally documented via `/sp.adr` once design decisions finalize (Phase 1-2).

---

## Testing Strategy

### Test Coverage by Feature

#### User Story 1: Content Access & Learning
**Test Objectives**: Verify all lessons load correctly, code examples execute, navigation works

**Test Cases**:
1. **Content Delivery Tests**
   - [ ] Lesson GET endpoint returns valid markdown with metadata
   - [ ] Module roadmap displays all 30+ lessons per module
   - [ ] Lesson navigation (Previous/Next) follows correct sequence
   - [ ] Code examples in response are syntactically valid (linted check)

2. **Performance Tests**
   - [ ] Page load time ≤ 3 seconds (p95) on simulated 5 Mbps connection
   - [ ] Concurrent lesson viewers (100+ simultaneous) don't degrade response time

3. **Code Example Tests**
   - [ ] All Python code examples execute in Python 3.11+ environment
   - [ ] All ROS 2 examples execute in ROS 2 Humble environment
   - [ ] All Gazebo examples run in Gazebo 11+ environment
   - [ ] Code output matches documented expectations

**Test Tools**: pytest (backend), Vitest (frontend), Playwright (E2E)

#### User Story 2: RAG Chatbot
**Test Objectives**: Verify RAG pipeline (Qdrant → LLM) produces accurate, cited responses

**Test Cases**:
1. **Query Processing Tests**
   - [ ] Query embedding matches lesson embeddings in Qdrant
   - [ ] Top-3 retrieved passages are semantically similar to query (>0.75 similarity)
   - [ ] Response time ≤ 5 seconds (p95)

2. **Accuracy Tests** (using ground truth dataset)
   - [ ] Chatbot responses match expert answers ≥ 80% of the time
   - [ ] Citations correctly link to source lessons
   - [ ] Out-of-scope queries (non-textbook topics) handled gracefully (error message instead of hallucination)

3. **Citation Tests**
   - [ ] Every response includes at least one citation
   - [ ] Citation format: "[Module, Lesson #.#]"
   - [ ] Cited lessons actually contain relevant passages

4. **Edge Case Tests**
   - [ ] Ambiguous queries (multiple interpretations) return "clarify query" message
   - [ ] Empty query handled gracefully
   - [ ] Extremely long query (10K tokens) doesn't crash backend
   - [ ] Non-English query (if multi-language) fails gracefully

**Test Tools**: pytest (integration tests with Qdrant test instance), manual ground truth validation

#### User Story 3: Authentication & Profiling
**Test Objectives**: Verify user signup, profile storage, session management

**Test Cases**:
1. **Signup Flow Tests**
   - [ ] Email validation (valid format required)
   - [ ] Duplicate email rejected (409 Conflict)
   - [ ] Optional password accepted
   - [ ] Specialization questionnaire persists to Neon
   - [ ] Rate limiting enforced (max 5 accounts per IP per hour)

2. **Profile Management Tests**
   - [ ] User can view their profile (GET /api/auth/profile)
   - [ ] User can update specialization (PATCH /api/auth/profile)
   - [ ] Profile changes persist across login/logout cycles
   - [ ] Password reset flow works (if supported)

3. **Session Tests**
   - [ ] Session token valid for 30 days (configurable)
   - [ ] Logout invalidates session
   - [ ] Unauthorized access to protected endpoints returns 401

4. **Data Persistence Tests**
   - [ ] User data correctly stored in Neon schema
   - [ ] Foreign key relationships enforced (user_id → user record)
   - [ ] Transaction rollback on error (e.g., profile update fails midway)

**Test Tools**: pytest with Neon test database, FastAPI TestClient

#### User Story 4: Personalization
**Test Objectives**: Verify recommendation engine tailors learning paths

**Test Cases**:
1. **Recommendation Generation Tests**
   - [ ] Beginner profile (ROS experience level = beginner) receives different recommendations than advanced profile
   - [ ] Recommendations align with user specialization tags
   - [ ] All four modules represented in recommendations (no over-recommendation of one module)
   - [ ] Recommendations update dynamically as user completes lessons

2. **Recommendation Ranking Tests**
   - [ ] Top recommended lessons have highest alignment score
   - [ ] Explanations provided ("Recommended because...")

3. **Engagement Tracking Tests** (if implicit feedback selected)
   - [ ] Click events logged to recommendation service
   - [ ] Completion events logged
   - [ ] Time-spent tracked accurately
   - [ ] Engagement metrics used to refine recommendations

**Test Tools**: pytest (unit/integration), database fixtures for test users

#### User Story 5: Multi-Language Support
**Test Objectives**: Verify translations accurate, code examples identical, user preferences persisted

**Test Cases**:
1. **Translation Content Tests**
   - [ ] Spanish translation of each lesson exists and is complete
   - [ ] Mandarin translation of each lesson exists and is complete
   - [ ] Code examples identical across all language versions (100% match)
   - [ ] Diagrams identical across versions

2. **Language Preference Tests**
   - [ ] User language preference saved to profile
   - [ ] Language preference persists across sessions
   - [ ] Content served in user's preferred language
   - [ ] Fallback to English if translation unavailable

3. **Quality Tests** (spot checks)
   - [ ] Spanish translation reviewed by native Spanish speaker (≥ 95% accuracy)
   - [ ] Mandarin translation reviewed by native Mandarin speaker (≥ 95% accuracy)

**Test Tools**: Manual review (native speakers), regex matching for code examples, Vitest (frontend language switching)

### Test Execution Timeline

| Phase | Test Focus | Test Types | Pass Criteria |
|-------|-----------|-----------|---------------|
| Phase B (Setup) | Infrastructure, APIs | Unit, contract | All endpoints respond correctly |
| Phase C (Content) | Content accuracy, reproducibility | Integration, code execution | All code examples pass, all claims verified |
| Phase D (Synthesis) | System integration, performance | E2E, load, accuracy | All success criteria met, <0.1% error rate |

---

## Specification Success Criteria (Validation Matrix)

This matrix maps specification success criteria (SC-001 through SC-030) to testing & quality gates:

| SC # | Metric | Validation Method | Responsible | Phase |
|------|--------|-------------------|-------------|-------|
| SC-001 | 30 lessons/module, verified accuracy | Content review + source check | Content Lead | C |
| SC-002 | All code examples execute | Automated pytest suite | QA | C |
| SC-003 | 90% module navigation success | User testing + analytics | Product | D |
| SC-004 | ≥85% lesson completion rate | Analytics tracking | Product | D |
| SC-005 | ≥4.0 content clarity rating | Post-lesson survey | Product | D |
| SC-006 | Chatbot response ≤5s (p95) | Load testing | DevOps | D |
| SC-007 | Answer relevance ≥0.8 | Ground truth comparison | QA | D |
| SC-008 | 80% responses cite sources | Response validation | QA | D |
| SC-009 | ≥95% out-of-scope handling | Query testing | QA | D |
| SC-010 | ≥4.0 chatbot helpfulness | User survey | Product | D |
| SC-011 | Signup ≤2 min (p90) | User testing | Product | D |
| SC-012 | ≥99% signup success | Analytics tracking | Product | D |
| SC-013 | 100% profile persistence | Database testing | QA | B-C |
| SC-014 | Zero unauthorized access | Security audit | Security | D |
| SC-015 | ≥80% recommendation coverage | Recommendation audit | QA | D |
| SC-016 | 30% higher completion via recommendations | A/B testing | Product | D |
| SC-017 | Proportional module recommendations | Recommendation audit | QA | D |
| SC-018 | 100% code example match | Regex validation | QA | D |
| SC-019 | ≥80% translation coverage in 30 days | Translation tracking | Content | D |
| SC-020 | ≥95% translation accuracy | Native review | Content | D |
| SC-021 | Page load ≤3s (p95) | Load testing | DevOps | D |
| SC-022 | ≥99.5% uptime | Monitoring | DevOps | D |
| SC-023 | ≥1000 concurrent users | Load testing | DevOps | D |
| SC-024 | <0.1% error rate | Log analysis | DevOps | D |
| SC-025 | ≥500 users in 90 days | Analytics | Product | Post-launch |
| SC-026 | ≥20% DAU | Analytics | Product | Post-launch |
| SC-027 | ≥50% MAU | Analytics | Product | Post-launch |
| SC-028 | ≥30% chatbot engagement | Analytics | Product | Post-launch |
| SC-029 | WCAG 2.1 AA pass rate | Axe accessibility audit | QA | B-D |
| SC-030 | Cross-browser compatible | BrowserStack testing | QA | D |
