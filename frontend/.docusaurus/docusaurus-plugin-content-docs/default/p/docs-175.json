{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","href":"/docs/intro","label":"Introduction to Physical AI & Humanoid Robotics","docId":"intro","unlisted":false},{"type":"category","label":"ROS 2 Fundamentals","items":[{"type":"link","href":"/docs/ros2/intro","label":"Introduction to ROS 2","docId":"ros2/intro","unlisted":false},{"type":"link","href":"/docs/ros2/architecture","label":"ROS 2 Architecture","docId":"ros2/architecture","unlisted":false},{"type":"link","href":"/docs/ros2/nodes","label":"ROS 2 Nodes","docId":"ros2/nodes","unlisted":false},{"type":"link","href":"/docs/ros2/topics","label":"ROS 2 Topics","docId":"ros2/topics","unlisted":false},{"type":"link","href":"/docs/ros2/services","label":"ROS 2 Services","docId":"ros2/services","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Digital Twin & Simulation","items":[{"type":"link","href":"/docs/digital-twin/intro","label":"Introduction to Digital Twin & Simulation","docId":"digital-twin/intro","unlisted":false},{"type":"link","href":"/docs/digital-twin/simulation-platforms","label":"Simulation Platforms for Digital Twins","docId":"digital-twin/simulation-platforms","unlisted":false},{"type":"link","href":"/docs/digital-twin/modeling","label":"Digital Twin Modeling","docId":"digital-twin/modeling","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"AI-Robot Brain","items":[{"type":"link","href":"/docs/ai-brain/intro","label":"Introduction to AI-Robot Brain","docId":"ai-brain/intro","unlisted":false},{"type":"link","href":"/docs/ai-brain/perception","label":"Perception Systems in AI-Robot Brains","docId":"ai-brain/perception","unlisted":false},{"type":"link","href":"/docs/ai-brain/planning","label":"Planning Systems in AI-Robot Brains","docId":"ai-brain/planning","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Vision Language Action (VLA)","items":[{"type":"link","href":"/docs/vla/intro","label":"Introduction to Vision Language Action (VLA)","docId":"vla/intro","unlisted":false},{"type":"link","href":"/docs/vla/architectures","label":"VLA System Architectures","docId":"vla/architectures","unlisted":false},{"type":"link","href":"/docs/vla/implementation","label":"VLA System Implementation","docId":"vla/implementation","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Advanced Topics","items":[{"type":"link","href":"/docs/advanced/contributing","label":"Contributing to the Textbook","docId":"advanced/contributing","unlisted":false},{"type":"link","href":"/docs/advanced/faq","label":"Frequently Asked Questions (FAQ)","docId":"advanced/faq","unlisted":false},{"type":"link","href":"/docs/advanced/humanoid-control","label":"Humanoid Robot Control","docId":"advanced/humanoid-control","unlisted":false},{"type":"link","href":"/docs/advanced/manipulation","label":"Robotic Manipulation","docId":"advanced/manipulation","unlisted":false},{"type":"link","href":"/docs/advanced/navigation","label":"Mobile Robot Navigation","docId":"advanced/navigation","unlisted":false},{"type":"link","href":"/docs/advanced/multi-robot","label":"Multi-Robot Systems","docId":"advanced/multi-robot","unlisted":false}],"collapsed":true,"collapsible":true}]},"docs":{"advanced/contributing":{"id":"advanced/contributing","title":"Contributing to the Textbook","description":"We welcome contributions to the Physical AI & Humanoid Robotics Textbook! This guide will help you get started with contributing content, examples, and improvements to the textbook.","sidebar":"tutorialSidebar"},"advanced/faq":{"id":"advanced/faq","title":"Frequently Asked Questions (FAQ)","description":"This section addresses common questions about the Physical AI & Humanoid Robotics Textbook and the concepts covered in the course.","sidebar":"tutorialSidebar"},"advanced/humanoid-control":{"id":"advanced/humanoid-control","title":"Humanoid Robot Control","description":"Humanoid robot control presents unique challenges due to the complex dynamics, balance requirements, and multi-degree-of-freedom systems. This section covers the fundamental concepts and techniques for controlling humanoid robots.","sidebar":"tutorialSidebar"},"advanced/manipulation":{"id":"advanced/manipulation","title":"Robotic Manipulation","description":"Robotic manipulation involves the control of robot arms and end-effectors to interact with objects in the environment. This section covers the fundamental concepts, techniques, and algorithms for dexterous manipulation.","sidebar":"tutorialSidebar"},"advanced/multi-robot":{"id":"advanced/multi-robot","title":"Multi-Robot Systems","description":"Multi-robot systems involve the coordination and control of multiple robots to achieve common goals. This section covers the fundamental concepts, coordination strategies, and implementation techniques for effective multi-robot cooperation.","sidebar":"tutorialSidebar"},"advanced/navigation":{"id":"advanced/navigation","title":"Mobile Robot Navigation","description":"Mobile robot navigation is the process of moving a robot from one location to another while avoiding obstacles and following optimal paths. This section covers the fundamental concepts, algorithms, and techniques for autonomous robot navigation.","sidebar":"tutorialSidebar"},"ai-brain/intro":{"id":"ai-brain/intro","title":"Introduction to AI-Robot Brain","description":"The AI-Robot Brain represents the cognitive architecture that enables robots to perceive their environment, reason about their situation, plan actions, and execute behaviors. This module covers the essential components that make robots intelligent and autonomous.","sidebar":"tutorialSidebar"},"ai-brain/perception":{"id":"ai-brain/perception","title":"Perception Systems in AI-Robot Brains","description":"Perception is the ability of a robot to understand its environment through sensors and interpret the data to make decisions. It's one of the fundamental components of an AI-Robot Brain, enabling robots to see, hear, and understand their surroundings.","sidebar":"tutorialSidebar"},"ai-brain/planning":{"id":"ai-brain/planning","title":"Planning Systems in AI-Robot Brains","description":"Planning is the process of determining a sequence of actions to achieve a desired goal. In AI-Robot Brains, planning systems bridge the gap between high-level goals and low-level motor commands, creating executable plans that account for environmental constraints and robot capabilities.","sidebar":"tutorialSidebar"},"digital-twin/intro":{"id":"digital-twin/intro","title":"Introduction to Digital Twin & Simulation","description":"A Digital Twin in robotics is a virtual representation of a physical robot that simulates its behavior, characteristics, and environment in real-time. This virtual model enables engineers to test, validate, and optimize robot designs and behaviors before deploying them to physical hardware.","sidebar":"tutorialSidebar"},"digital-twin/modeling":{"id":"digital-twin/modeling","title":"Digital Twin Modeling","description":"Digital twin modeling involves creating accurate virtual representations of physical robots and their environments. This process is crucial for developing, testing, and validating robotic systems before deploying them to physical hardware.","sidebar":"tutorialSidebar"},"digital-twin/simulation-platforms":{"id":"digital-twin/simulation-platforms","title":"Simulation Platforms for Digital Twins","description":"Simulation platforms are essential tools for creating and managing digital twins of physical robots. These platforms provide the virtual environment where digital twins can be tested, validated, and optimized before deployment to physical hardware.","sidebar":"tutorialSidebar"},"intro":{"id":"intro","title":"Introduction to Physical AI & Humanoid Robotics","description":"Welcome to the AI-Native Physical AI & Humanoid Robotics Textbook! This comprehensive guide will take you through the fundamental concepts and advanced techniques needed to understand and develop humanoid robots.","sidebar":"tutorialSidebar"},"ros2/architecture":{"id":"ros2/architecture","title":"ROS 2 Architecture","description":"Understanding the architecture of ROS 2 is crucial for developing effective robotic applications. The architecture is built around several core concepts and technologies.","sidebar":"tutorialSidebar"},"ros2/intro":{"id":"ros2/intro","title":"Introduction to ROS 2","description":"The Robot Operating System 2 (ROS 2) is a flexible framework for writing robot software. It's a collection of tools, libraries, and conventions that aim to simplify the task of creating complex and robust robot behavior across a wide variety of robot platforms.","sidebar":"tutorialSidebar"},"ros2/nodes":{"id":"ros2/nodes","title":"ROS 2 Nodes","description":"A node is a single executable that uses ROS 2 to communicate with other nodes. Nodes are the fundamental building blocks of ROS 2 applications, each performing a specific task or set of tasks.","sidebar":"tutorialSidebar"},"ros2/services":{"id":"ros2/services","title":"ROS 2 Services","description":"Services provide a request-response communication pattern in ROS 2. Unlike topics which are asynchronous, services provide synchronous communication where a client sends a request and waits for a response from a server.","sidebar":"tutorialSidebar"},"ros2/topics":{"id":"ros2/topics","title":"ROS 2 Topics","description":"Topics are named buses over which nodes exchange messages. They provide a way for nodes to communicate with each other using a publish-subscribe pattern.","sidebar":"tutorialSidebar"},"vla/architectures":{"id":"vla/architectures","title":"VLA System Architectures","description":"Vision Language Action (VLA) systems require sophisticated architectures that seamlessly integrate perception, language understanding, and action execution. These architectures must handle the complexity of multimodal processing while maintaining real-time performance for robotic applications.","sidebar":"tutorialSidebar"},"vla/implementation":{"id":"vla/implementation","title":"VLA System Implementation","description":"Implementing Vision Language Action (VLA) systems requires careful integration of multiple complex components. This guide covers practical implementation strategies, code examples, and best practices for building robust VLA systems.","sidebar":"tutorialSidebar"},"vla/intro":{"id":"vla/intro","title":"Introduction to Vision Language Action (VLA)","description":"Vision Language Action (VLA) systems represent the next frontier in robotics, where robots can understand natural language instructions, perceive their environment visually, and execute complex actions. This paradigm enables more intuitive human-robot interaction and more flexible robotic capabilities.","sidebar":"tutorialSidebar"}}}}