{"allContent":{"docusaurus-plugin-content-docs":{"default":{"loadedVersions":[{"versionName":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","path":"/docs","tagsPath":"/docs/tags","isLast":true,"routePriority":-1,"sidebarFilePath":"D:\\hackathon\\physical-ai-robotics\\frontend\\sidebars.js","contentPath":"D:\\hackathon\\physical-ai-robotics\\frontend\\docs","docs":[{"id":"advanced/contributing","title":"Contributing to the Textbook","description":"We welcome contributions to the Physical AI & Humanoid Robotics Textbook! This guide will help you get started with contributing content, examples, and improvements to the textbook.","source":"@site/docs/advanced/contributing.md","sourceDirName":"advanced","slug":"/advanced/contributing","permalink":"/docs/advanced/contributing","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"VLA System Implementation","permalink":"/docs/vla/implementation"},"next":{"title":"Frequently Asked Questions (FAQ)","permalink":"/docs/advanced/faq"}},{"id":"advanced/faq","title":"Frequently Asked Questions (FAQ)","description":"This section addresses common questions about the Physical AI & Humanoid Robotics Textbook and the concepts covered in the course.","source":"@site/docs/advanced/faq.md","sourceDirName":"advanced","slug":"/advanced/faq","permalink":"/docs/advanced/faq","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Contributing to the Textbook","permalink":"/docs/advanced/contributing"},"next":{"title":"Humanoid Robot Control","permalink":"/docs/advanced/humanoid-control"}},{"id":"advanced/humanoid-control","title":"Humanoid Robot Control","description":"Humanoid robot control presents unique challenges due to the complex dynamics, balance requirements, and multi-degree-of-freedom systems. This section covers the fundamental concepts and techniques for controlling humanoid robots.","source":"@site/docs/advanced/humanoid-control.md","sourceDirName":"advanced","slug":"/advanced/humanoid-control","permalink":"/docs/advanced/humanoid-control","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Frequently Asked Questions (FAQ)","permalink":"/docs/advanced/faq"},"next":{"title":"Robotic Manipulation","permalink":"/docs/advanced/manipulation"}},{"id":"advanced/manipulation","title":"Robotic Manipulation","description":"Robotic manipulation involves the control of robot arms and end-effectors to interact with objects in the environment. This section covers the fundamental concepts, techniques, and algorithms for dexterous manipulation.","source":"@site/docs/advanced/manipulation.md","sourceDirName":"advanced","slug":"/advanced/manipulation","permalink":"/docs/advanced/manipulation","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"Humanoid Robot Control","permalink":"/docs/advanced/humanoid-control"},"next":{"title":"Mobile Robot Navigation","permalink":"/docs/advanced/navigation"}},{"id":"advanced/multi-robot","title":"Multi-Robot Systems","description":"Multi-robot systems involve the coordination and control of multiple robots to achieve common goals. This section covers the fundamental concepts, coordination strategies, and implementation techniques for effective multi-robot cooperation.","source":"@site/docs/advanced/multi-robot.md","sourceDirName":"advanced","slug":"/advanced/multi-robot","permalink":"/docs/advanced/multi-robot","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_position":6},"sidebar":"tutorialSidebar","previous":{"title":"Mobile Robot Navigation","permalink":"/docs/advanced/navigation"}},{"id":"advanced/navigation","title":"Mobile Robot Navigation","description":"Mobile robot navigation is the process of moving a robot from one location to another while avoiding obstacles and following optimal paths. This section covers the fundamental concepts, algorithms, and techniques for autonomous robot navigation.","source":"@site/docs/advanced/navigation.md","sourceDirName":"advanced","slug":"/advanced/navigation","permalink":"/docs/advanced/navigation","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5},"sidebar":"tutorialSidebar","previous":{"title":"Robotic Manipulation","permalink":"/docs/advanced/manipulation"},"next":{"title":"Multi-Robot Systems","permalink":"/docs/advanced/multi-robot"}},{"id":"ai-brain/intro","title":"Introduction to AI-Robot Brain","description":"The AI-Robot Brain represents the cognitive architecture that enables robots to perceive their environment, reason about their situation, plan actions, and execute behaviors. This module covers the essential components that make robots intelligent and autonomous.","source":"@site/docs/ai-brain/intro.md","sourceDirName":"ai-brain","slug":"/ai-brain/intro","permalink":"/docs/ai-brain/intro","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Digital Twin Modeling","permalink":"/docs/digital-twin/modeling"},"next":{"title":"Perception Systems in AI-Robot Brains","permalink":"/docs/ai-brain/perception"}},{"id":"ai-brain/perception","title":"Perception Systems in AI-Robot Brains","description":"Perception is the ability of a robot to understand its environment through sensors and interpret the data to make decisions. It's one of the fundamental components of an AI-Robot Brain, enabling robots to see, hear, and understand their surroundings.","source":"@site/docs/ai-brain/perception.md","sourceDirName":"ai-brain","slug":"/ai-brain/perception","permalink":"/docs/ai-brain/perception","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Introduction to AI-Robot Brain","permalink":"/docs/ai-brain/intro"},"next":{"title":"Planning Systems in AI-Robot Brains","permalink":"/docs/ai-brain/planning"}},{"id":"ai-brain/planning","title":"Planning Systems in AI-Robot Brains","description":"Planning is the process of determining a sequence of actions to achieve a desired goal. In AI-Robot Brains, planning systems bridge the gap between high-level goals and low-level motor commands, creating executable plans that account for environmental constraints and robot capabilities.","source":"@site/docs/ai-brain/planning.md","sourceDirName":"ai-brain","slug":"/ai-brain/planning","permalink":"/docs/ai-brain/planning","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Perception Systems in AI-Robot Brains","permalink":"/docs/ai-brain/perception"},"next":{"title":"Introduction to Vision Language Action (VLA)","permalink":"/docs/vla/intro"}},{"id":"digital-twin/intro","title":"Introduction to Digital Twin & Simulation","description":"A Digital Twin in robotics is a virtual representation of a physical robot that simulates its behavior, characteristics, and environment in real-time. This virtual model enables engineers to test, validate, and optimize robot designs and behaviors before deploying them to physical hardware.","source":"@site/docs/digital-twin/intro.md","sourceDirName":"digital-twin","slug":"/digital-twin/intro","permalink":"/docs/digital-twin/intro","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"ROS 2 Services","permalink":"/docs/ros2/services"},"next":{"title":"Simulation Platforms for Digital Twins","permalink":"/docs/digital-twin/simulation-platforms"}},{"id":"digital-twin/modeling","title":"Digital Twin Modeling","description":"Digital twin modeling involves creating accurate virtual representations of physical robots and their environments. This process is crucial for developing, testing, and validating robotic systems before deploying them to physical hardware.","source":"@site/docs/digital-twin/modeling.md","sourceDirName":"digital-twin","slug":"/digital-twin/modeling","permalink":"/docs/digital-twin/modeling","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Simulation Platforms for Digital Twins","permalink":"/docs/digital-twin/simulation-platforms"},"next":{"title":"Introduction to AI-Robot Brain","permalink":"/docs/ai-brain/intro"}},{"id":"digital-twin/simulation-platforms","title":"Simulation Platforms for Digital Twins","description":"Simulation platforms are essential tools for creating and managing digital twins of physical robots. These platforms provide the virtual environment where digital twins can be tested, validated, and optimized before deployment to physical hardware.","source":"@site/docs/digital-twin/simulation-platforms.md","sourceDirName":"digital-twin","slug":"/digital-twin/simulation-platforms","permalink":"/docs/digital-twin/simulation-platforms","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Introduction to Digital Twin & Simulation","permalink":"/docs/digital-twin/intro"},"next":{"title":"Digital Twin Modeling","permalink":"/docs/digital-twin/modeling"}},{"id":"intro","title":"Introduction to Physical AI & Humanoid Robotics","description":"Welcome to the AI-Native Physical AI & Humanoid Robotics Textbook! This comprehensive guide will take you through the fundamental concepts and advanced techniques needed to understand and develop humanoid robots.","source":"@site/docs/intro.md","sourceDirName":".","slug":"/intro","permalink":"/docs/intro","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","next":{"title":"Introduction to ROS 2","permalink":"/docs/ros2/intro"}},{"id":"ros2/architecture","title":"ROS 2 Architecture","description":"Understanding the architecture of ROS 2 is crucial for developing effective robotic applications. The architecture is built around several core concepts and technologies.","source":"@site/docs/ros2/architecture.md","sourceDirName":"ros2","slug":"/ros2/architecture","permalink":"/docs/ros2/architecture","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Introduction to ROS 2","permalink":"/docs/ros2/intro"},"next":{"title":"ROS 2 Nodes","permalink":"/docs/ros2/nodes"}},{"id":"ros2/intro","title":"Introduction to ROS 2","description":"The Robot Operating System 2 (ROS 2) is a flexible framework for writing robot software. It's a collection of tools, libraries, and conventions that aim to simplify the task of creating complex and robust robot behavior across a wide variety of robot platforms.","source":"@site/docs/ros2/intro.md","sourceDirName":"ros2","slug":"/ros2/intro","permalink":"/docs/ros2/intro","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Introduction to Physical AI & Humanoid Robotics","permalink":"/docs/intro"},"next":{"title":"ROS 2 Architecture","permalink":"/docs/ros2/architecture"}},{"id":"ros2/nodes","title":"ROS 2 Nodes","description":"A node is a single executable that uses ROS 2 to communicate with other nodes. Nodes are the fundamental building blocks of ROS 2 applications, each performing a specific task or set of tasks.","source":"@site/docs/ros2/nodes.md","sourceDirName":"ros2","slug":"/ros2/nodes","permalink":"/docs/ros2/nodes","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"ROS 2 Architecture","permalink":"/docs/ros2/architecture"},"next":{"title":"ROS 2 Topics","permalink":"/docs/ros2/topics"}},{"id":"ros2/services","title":"ROS 2 Services","description":"Services provide a request-response communication pattern in ROS 2. Unlike topics which are asynchronous, services provide synchronous communication where a client sends a request and waits for a response from a server.","source":"@site/docs/ros2/services.md","sourceDirName":"ros2","slug":"/ros2/services","permalink":"/docs/ros2/services","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"ROS 2 Topics","permalink":"/docs/ros2/topics"},"next":{"title":"Introduction to Digital Twin & Simulation","permalink":"/docs/digital-twin/intro"}},{"id":"ros2/topics","title":"ROS 2 Topics","description":"Topics are named buses over which nodes exchange messages. They provide a way for nodes to communicate with each other using a publish-subscribe pattern.","source":"@site/docs/ros2/topics.md","sourceDirName":"ros2","slug":"/ros2/topics","permalink":"/docs/ros2/topics","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"ROS 2 Nodes","permalink":"/docs/ros2/nodes"},"next":{"title":"ROS 2 Services","permalink":"/docs/ros2/services"}},{"id":"vla/architectures","title":"VLA System Architectures","description":"Vision Language Action (VLA) systems require sophisticated architectures that seamlessly integrate perception, language understanding, and action execution. These architectures must handle the complexity of multimodal processing while maintaining real-time performance for robotic applications.","source":"@site/docs/vla/architectures.md","sourceDirName":"vla","slug":"/vla/architectures","permalink":"/docs/vla/architectures","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Introduction to Vision Language Action (VLA)","permalink":"/docs/vla/intro"},"next":{"title":"VLA System Implementation","permalink":"/docs/vla/implementation"}},{"id":"vla/implementation","title":"VLA System Implementation","description":"Implementing Vision Language Action (VLA) systems requires careful integration of multiple complex components. This guide covers practical implementation strategies, code examples, and best practices for building robust VLA systems.","source":"@site/docs/vla/implementation.md","sourceDirName":"vla","slug":"/vla/implementation","permalink":"/docs/vla/implementation","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"VLA System Architectures","permalink":"/docs/vla/architectures"},"next":{"title":"Contributing to the Textbook","permalink":"/docs/advanced/contributing"}},{"id":"vla/intro","title":"Introduction to Vision Language Action (VLA)","description":"Vision Language Action (VLA) systems represent the next frontier in robotics, where robots can understand natural language instructions, perceive their environment visually, and execute complex actions. This paradigm enables more intuitive human-robot interaction and more flexible robotic capabilities.","source":"@site/docs/vla/intro.md","sourceDirName":"vla","slug":"/vla/intro","permalink":"/docs/vla/intro","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Planning Systems in AI-Robot Brains","permalink":"/docs/ai-brain/planning"},"next":{"title":"VLA System Architectures","permalink":"/docs/vla/architectures"}}],"drafts":[],"sidebars":{"tutorialSidebar":[{"type":"doc","id":"intro"},{"type":"category","label":"ROS 2 Fundamentals","items":[{"type":"doc","id":"ros2/intro"},{"type":"doc","id":"ros2/architecture"},{"type":"doc","id":"ros2/nodes"},{"type":"doc","id":"ros2/topics"},{"type":"doc","id":"ros2/services"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Digital Twin & Simulation","items":[{"type":"doc","id":"digital-twin/intro"},{"type":"doc","id":"digital-twin/simulation-platforms"},{"type":"doc","id":"digital-twin/modeling"}],"collapsed":true,"collapsible":true},{"type":"category","label":"AI-Robot Brain","items":[{"type":"doc","id":"ai-brain/intro"},{"type":"doc","id":"ai-brain/perception"},{"type":"doc","id":"ai-brain/planning"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Vision Language Action (VLA)","items":[{"type":"doc","id":"vla/intro"},{"type":"doc","id":"vla/architectures"},{"type":"doc","id":"vla/implementation"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Advanced Topics","items":[{"type":"doc","id":"advanced/contributing"},{"type":"doc","id":"advanced/faq"},{"type":"doc","id":"advanced/humanoid-control"},{"type":"doc","id":"advanced/manipulation"},{"type":"doc","id":"advanced/navigation"},{"type":"doc","id":"advanced/multi-robot"}],"collapsed":true,"collapsible":true}]}}]}},"docusaurus-plugin-content-pages":{"default":[{"type":"jsx","permalink":"/","source":"@site/src/pages/index.js"},{"type":"jsx","permalink":"/login","source":"@site/src/pages/login.js"},{"type":"jsx","permalink":"/signup","source":"@site/src/pages/signup.js"}]},"docusaurus-plugin-debug":{},"docusaurus-plugin-svgr":{},"docusaurus-theme-classic":{},"docusaurus-bootstrap-plugin":{},"docusaurus-mdx-fallback-plugin":{}}}